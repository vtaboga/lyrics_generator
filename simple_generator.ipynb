{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "\n",
    "from keras.layers import Dense, TimeDistributed, Activation\n",
    "from keras.layers import LSTM, Dropout\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(1919788)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usefull functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dictionnaries :\n",
    "char_to_ix = np.load('char_to_ix.npy').item()\n",
    "ix_to_char = np.load('ix_to_char.npy').item()\n",
    "chars = np.load('chars.npy').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(csv_path, artists = None) :\n",
    "    \"\"\"read csv file with pandas\n",
    "    keep specific songs of an artist\n",
    "    return df and number of songs\"\"\"\n",
    "    \n",
    "    data = pd.read_csv(\"songdata.csv\")\n",
    "    if artists :\n",
    "        data = data[data.artist.isin(artists)].reset_index()\n",
    "    n_songs = len(data)\n",
    "    return data, n_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_encoder(song, char_to_ix):\n",
    "    \"\"\"change str characters with matching encode number\"\"\"\n",
    "    encoded = [char_to_ix[char] for _,char in enumerate(song)]\n",
    "\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_lines(song) :\n",
    "    \"\"\"separate lines of a song\n",
    "    input : lyrics (str)\n",
    "    output : list of every lines\"\"\"\n",
    "    \n",
    "    song_lyrics = []\n",
    "    line = \"\"\n",
    "\n",
    "    for i in range(len(song)):\n",
    "        #add the caracter to the line\n",
    "        line+=song[i]\n",
    "        #check two following caracters to spot the \\\\n\n",
    "        if song[i]==\"\\n\" :\n",
    "            #cut the str to end the line\n",
    "            song_lyrics.append(line[:len(line)-2])\n",
    "            #start another line\n",
    "            line =''\n",
    "            \n",
    "    return song_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequences(encoded_text, sequence_length):\n",
    "    sequences = []\n",
    "    n_sequences = int(len(encoded_text)/sequence_length)\n",
    "    for i in range(n_sequences):\n",
    "        sequences.append(encoded_text[i*sequence_length:(i+1)*sequence_length])\n",
    "    return(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence(seq, max_length, pad_label=100):\n",
    "    \n",
    "    seq += [pad_label for i in range(max_length - len(seq))]\n",
    "    \n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_str(n_songs, df):\n",
    "    \"\"\"concatenate lyrics from the n_songs of a df\"\"\"\n",
    "    songs_conc = \"\"\n",
    "    for i in range(n_songs):\n",
    "        songs_conc += df.iloc[i].text\n",
    "    return songs_conc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embeds_array(array, n_chars, n_sequences, max_sequence_length):\n",
    "    \"\"\"inputs : 2 dim array of padded encoded sequences and number of char\n",
    "    outputs : 3 dim array, replace each encoded char by a one hot vector\"\"\"\n",
    "    \n",
    "    #create an empty array of the rigth dimension\n",
    "    output = np.zeros((n_sequences, max_sequence_length, n_chars+1))\n",
    "\n",
    "    for seq in range(n_sequences):\n",
    "        for char in range(max_sequence_length):\n",
    "            label = array[seq][char]\n",
    "            #100 = pad label\n",
    "            if label != 100 : \n",
    "                output[seq][char][label] = 1\n",
    "            else :\n",
    "                #replace the last number by 1 (pad label)\n",
    "                output[seq][char][-1] = 1\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embeds_array_wp(array, n_chars, n_sequences, max_sequence_length):\n",
    "    \"\"\"inputs : 2 dim array of padded encoded sequences and number of char\n",
    "    outputs : 3 dim array, replace each encoded char by a one hot vector\"\"\"\n",
    "    \n",
    "    #create an empty array of the rigth dimension\n",
    "    output = np.zeros((n_sequences, max_sequence_length, n_chars))\n",
    "\n",
    "    for seq in range(n_sequences):\n",
    "        for char in range(max_sequence_length):\n",
    "            label = array[seq][char] \n",
    "            output[seq][char][label] = 1\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shaping_data(csv_path, artists, char_to_ix, padding = True, max_sentence_length = 50):\n",
    "    \n",
    "    #load the songs\n",
    "    df, n_songs = load_data(csv_path,artists)\n",
    "    \n",
    "    #gather all the songs in one big str\n",
    "    songs_conc = concat_str(n_songs, df)\n",
    "    \n",
    "    if padding :\n",
    "        #create a list of the lines of our dataset\n",
    "        sequences = split_lines(songs_conc)\n",
    "        #find the longest sentence :\n",
    "        max_sentence_length = len(max(sequences, key=len))\n",
    "        #change char for matching char to ix index\n",
    "        encoded_sequences = [seq_encoder(sequences[i], char_to_ix) for i in range(len(sequences))]\n",
    "        #remove empty sequences\n",
    "        encoded_sequences = [encoded_sequences[i] for i in range(len(encoded_sequences)) if len(encoded_sequences[i])>1]\n",
    "        #pad sequences according to the longest setence in the all df \n",
    "        #in this way the nn dimensions are independent of the chosen artist\n",
    "        encoded_sequences = [pad_sequence(encoded_sequences[i], max_sentence_length) for i in range(len(encoded_sequences))]\n",
    "        \n",
    "    else :\n",
    "        #change char for matching char_to_ix index\n",
    "        encoded_sequences = seq_encoder(songs_conc, char_to_ix)\n",
    "        #split text in size-learnable sequences\n",
    "        encoded_sequences = split_sequences(encoded_sequences, sequence_length)\n",
    "        \n",
    "    #prepare the input and output sequences by slicing the input by one character :\n",
    "    n_sequences = len(encoded_sequences)\n",
    "\n",
    "    #slice inputs and outputs by one char\n",
    "    inputs = [encoded_sequences[i][:-1] for i in range(n_sequences)]\n",
    "    outputs = [encoded_sequences[i][1:] for i in range(n_sequences)]\n",
    "    \n",
    "    #embeds the inputs and outputs\n",
    "    inputs_embedded = embeds_array(array = inputs, n_chars = len(char_to_ix), \n",
    "                               n_sequences = n_sequences, \n",
    "                               max_sequence_length = max_sentence_length-1)\n",
    "\n",
    "    outputs_embedded = embeds_array(array = outputs, n_chars = len(char_to_ix), \n",
    "                               n_sequences = n_sequences, \n",
    "                               max_sequence_length = max_sentence_length-1)\n",
    "    \n",
    "    return(inputs_embedded, outputs_embedded, max_sentence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process data\n",
    "artists = ['Elton John', 'Eminem','Queen']\n",
    "inputs_embedded, outputs_embedded, max_sentence_length = shaping_data(\"songdata.csv\",artists,char_to_ix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters :\n",
    "hidden_dim = 514\n",
    "num_layers = 1\n",
    "vocab_size = len(char_to_ix)\n",
    "sentence_length = max_sentence_length -1 #-1 for slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, None, 514)         1217152   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, None, 514)         0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, None, 77)          39655     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, None, 77)          0         \n",
      "=================================================================\n",
      "Total params: 1,256,807\n",
      "Trainable params: 1,256,807\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(LSTM(hidden_dim, input_shape=(None, vocab_size+1), return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "#TimeDistributed to do many to many\n",
    "model.add(TimeDistributed(Dense(vocab_size+1)))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"Adam\")\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lyrics Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lyrics_generator(model, length, vocab_size, first_word=None, padding = True):\n",
    "    \n",
    "    if padding :\n",
    "        #add pad label to ix_to_char\n",
    "        ix_to_char[76]=\"*\"\n",
    "    \n",
    "    sentence = np.zeros((1, length, vocab_size))\n",
    "    \n",
    "    if not first_word :\n",
    "        #label of the first character\n",
    "        ix = [np.random.randint(1,vocab_size)]\n",
    "        y_char = [ix_to_char[ix[-1]]]\n",
    "        \n",
    "    else :\n",
    "        y_char = [char for _,char in enumerate(first_word)]\n",
    "        ix = seq_encoder(first_word, char_to_ix)\n",
    "        \n",
    "    #fill the first characters\n",
    "    for i in range(len(ix)):\n",
    "        sentence[0, i, :][ix[i]] = 1\n",
    "\n",
    "    for i in range(len(ix),length):\n",
    "        #starting from \n",
    "        #fill the one hot vector of the corresponding caracter\n",
    "        sentence[0, i, :][ix[-1]] = 1\n",
    "        \n",
    "        ix = np.argmax(model.predict(sentence[:, :i+1, :])[0], 1)\n",
    "        y_char.append(ix_to_char[ix[-1]])\n",
    "        \n",
    "    lyrics = ''\n",
    "    for i in range(length):\n",
    "        lyrics += y_char[i]\n",
    "        \n",
    "    return lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** epoch 0 *****\n",
      "Epoch 1/1\n",
      "15655/15655 [==============================] - 197s 13ms/step - loss: 1.2640\n",
      "***** epoch 1 *****\n",
      "Epoch 1/1\n",
      "15655/15655 [==============================] - 201s 13ms/step - loss: 0.9354\n",
      "***** epoch 2 *****\n",
      "Epoch 1/1\n",
      "15655/15655 [==============================] - 205s 13ms/step - loss: 0.8493\n",
      "***** epoch 3 *****\n",
      "Epoch 1/1\n",
      "15655/15655 [==============================] - 203s 13ms/step - loss: 0.7932\n",
      "***** epoch 4 *****\n",
      "Epoch 1/1\n",
      "15655/15655 [==============================] - 201s 13ms/step - loss: 0.7510\n",
      "***** epoch 5 *****\n",
      "Epoch 1/1\n",
      "15655/15655 [==============================] - 203s 13ms/step - loss: 0.7177\n",
      "***** epoch 6 *****\n",
      "Epoch 1/1\n",
      "15655/15655 [==============================] - 215s 14ms/step - loss: 0.6892\n",
      "***** epoch 7 *****\n",
      "Epoch 1/1\n",
      "15655/15655 [==============================] - 224s 14ms/step - loss: 0.6646\n",
      "***** epoch 8 *****\n",
      "Epoch 1/1\n",
      "15655/15655 [==============================] - 237s 15ms/step - loss: 0.6409\n",
      "***** epoch 9 *****\n",
      "Epoch 1/1\n",
      "15655/15655 [==============================] - 223s 14ms/step - loss: 0.6187\n",
      "***** epoch 10 *****\n",
      "Epoch 1/1\n",
      "15655/15655 [==============================] - 224s 14ms/step - loss: 0.5990\n",
      "***** epoch 11 *****\n",
      "Epoch 1/1\n",
      "15655/15655 [==============================] - 217s 14ms/step - loss: 0.5794\n",
      "***** epoch 12 *****\n",
      "Epoch 1/1\n",
      "15655/15655 [==============================] - 227s 14ms/step - loss: 0.5612\n",
      "***** epoch 13 *****\n",
      "Epoch 1/1\n",
      "15655/15655 [==============================] - 234s 15ms/step - loss: 0.5436\n",
      "***** epoch 14 *****\n",
      "Epoch 1/1\n",
      "15655/15655 [==============================] - 231s 15ms/step - loss: 0.5270\n",
      "***** epoch 15 *****\n",
      "Epoch 1/1\n",
      "15655/15655 [==============================] - 231s 15ms/step - loss: 0.5121\n",
      "***** epoch 16 *****\n",
      "Epoch 1/1\n",
      "15655/15655 [==============================] - 231s 15ms/step - loss: 0.4981\n",
      "***** epoch 17 *****\n",
      "Epoch 1/1\n",
      "15655/15655 [==============================] - 233s 15ms/step - loss: 0.4841\n",
      "***** epoch 18 *****\n",
      "Epoch 1/1\n",
      "15655/15655 [==============================] - 226s 14ms/step - loss: 0.4720\n",
      "***** epoch 19 *****\n",
      "Epoch 1/1\n",
      "15655/15655 [==============================] - 228s 15ms/step - loss: 0.4603\n",
      "***** epoch 20 *****\n",
      "Epoch 1/1\n",
      "15655/15655 [==============================] - 227s 15ms/step - loss: 0.4489\n",
      "***** epoch 21 *****\n",
      "Epoch 1/1\n",
      "15655/15655 [==============================] - 213s 14ms/step - loss: 0.4385\n",
      "***** epoch 22 *****\n",
      "Epoch 1/1\n",
      "15655/15655 [==============================] - 220s 14ms/step - loss: 0.4306\n",
      "***** epoch 23 *****\n",
      "Epoch 1/1\n",
      "15655/15655 [==============================] - 249s 16ms/step - loss: 0.4212\n",
      "***** epoch 24 *****\n",
      "Epoch 1/1\n",
      "15655/15655 [==============================] - 232s 15ms/step - loss: 0.4139\n",
      "***** epoch 25 *****\n",
      "Epoch 1/1\n",
      "15655/15655 [==============================] - 221s 14ms/step - loss: 0.4058\n",
      "***** epoch 26 *****\n",
      "Epoch 1/1\n",
      "15655/15655 [==============================] - 227s 15ms/step - loss: 0.3994\n",
      "***** epoch 27 *****\n",
      "Epoch 1/1\n",
      "15655/15655 [==============================] - 244s 16ms/step - loss: 0.3941\n",
      "***** epoch 28 *****\n",
      "Epoch 1/1\n",
      "15655/15655 [==============================] - 232s 15ms/step - loss: 0.3879\n",
      "***** epoch 29 *****\n",
      "Epoch 1/1\n",
      "15655/15655 [==============================] - 221s 14ms/step - loss: 0.3818\n",
      "***** epoch 30 *****\n",
      "Epoch 1/1\n",
      "15655/15655 [==============================] - 217s 14ms/step - loss: 0.3771\n",
      "***** epoch 31 *****\n",
      "Epoch 1/1\n",
      "15655/15655 [==============================] - 240s 15ms/step - loss: 0.3722\n",
      "***** epoch 32 *****\n",
      "Epoch 1/1\n",
      "15655/15655 [==============================] - 219s 14ms/step - loss: 0.3671\n",
      "***** epoch 33 *****\n",
      "Epoch 1/1\n",
      "15655/15655 [==============================] - 220s 14ms/step - loss: 0.3629\n",
      "***** epoch 34 *****\n",
      "Epoch 1/1\n",
      "15655/15655 [==============================] - 216s 14ms/step - loss: 0.3586\n",
      "***** epoch 35 *****\n",
      "Epoch 1/1\n",
      "15655/15655 [==============================] - 211s 13ms/step - loss: 0.3555\n",
      "***** epoch 36 *****\n",
      "Epoch 1/1\n",
      "15655/15655 [==============================] - 223s 14ms/step - loss: 0.3517\n",
      "***** epoch 37 *****\n",
      "Epoch 1/1\n",
      "15655/15655 [==============================] - 251s 16ms/step - loss: 0.3487\n",
      "***** epoch 38 *****\n",
      "Epoch 1/1\n",
      "15655/15655 [==============================] - 236s 15ms/step - loss: 0.3451\n",
      "***** epoch 39 *****\n",
      "Epoch 1/1\n",
      "15655/15655 [==============================] - 235s 15ms/step - loss: 0.3421\n",
      "***** epoch 40 *****\n",
      "Epoch 1/1\n",
      "15655/15655 [==============================] - 245s 16ms/step - loss: 0.3389\n",
      "***** epoch 41 *****\n",
      "Epoch 1/1\n",
      "15655/15655 [==============================] - 238s 15ms/step - loss: 0.3357\n",
      "***** epoch 42 *****\n",
      "Epoch 1/1\n",
      "15655/15655 [==============================] - 217s 14ms/step - loss: 0.3347\n",
      "***** epoch 43 *****\n",
      "Epoch 1/1\n",
      "15655/15655 [==============================] - 211s 13ms/step - loss: 0.3316\n",
      "***** epoch 44 *****\n",
      "Epoch 1/1\n",
      "15655/15655 [==============================] - 240s 15ms/step - loss: 0.3290\n",
      "***** epoch 45 *****\n",
      "Epoch 1/1\n",
      "15655/15655 [==============================] - 262s 17ms/step - loss: 0.3263\n",
      "***** epoch 46 *****\n",
      "Epoch 1/1\n",
      "15655/15655 [==============================] - 255s 16ms/step - loss: 0.3238\n",
      "***** epoch 47 *****\n",
      "Epoch 1/1\n",
      "15655/15655 [==============================] - 237s 15ms/step - loss: 0.3224\n",
      "***** epoch 48 *****\n",
      "Epoch 1/1\n",
      "15655/15655 [==============================] - 239s 15ms/step - loss: 0.3201\n",
      "***** epoch 49 *****\n",
      "Epoch 1/1\n",
      "15655/15655 [==============================] - 214s 14ms/step - loss: 0.3177\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 50\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print('***** epoch '+str(epoch)+\" *****\")\n",
    "    model.fit(inputs_embedded, outputs_embedded, batch_size=32, verbose=1)\n",
    "    #if epoch % 10 == 0:\n",
    "    #    model.save_weights('checkpoint_{}_epoch_{}.hdf5'.format(hidden_dim, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_weights('checkpoint_lyrgen.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_song = lyrics_generator(model, 50, len(char_to_ix)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and to say you and they go to the shave me ******\n"
     ]
    }
   ],
   "source": [
    "print(new_song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
