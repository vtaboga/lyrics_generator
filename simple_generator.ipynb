{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "\n",
    "import torch.utils.data as data\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "np.random.seed(1919788)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for padding purpuses, with have been once through out the  all corpus to find the longest sentence :\n",
    "max_sentence_length = 114\n",
    "\n",
    "#load dictionnaries :\n",
    "char_to_ix = np.load('char_to_ix.npy').item()\n",
    "ix_to_char = np.load('ix_to_char.npy').item()\n",
    "chars = np.load('chars.npy').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_encoder(song, char_to_ix):\n",
    "    \"\"\"change str characters with matching encode number\"\"\"\n",
    "    encoded = [char_to_ix[char] for _,char in enumerate(song)]\n",
    "\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(csv_path, artists = None) :\n",
    "    \"\"\"read csv file with pandas\n",
    "    keep specific songs of an artist\n",
    "    return df and number of songs\"\"\"\n",
    "    \n",
    "    data = pd.read_csv(\"songdata.csv\")\n",
    "    if artists :\n",
    "        data = data[data.artist.isin(artists)].reset_index()\n",
    "    n_songs = len(data)\n",
    "    return data, n_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_lines(song) :\n",
    "    \"\"\"separate lines of a song\n",
    "    input : lyrics (str)\n",
    "    output : list of every lines\"\"\"\n",
    "    \n",
    "    song_lyrics = []\n",
    "    line = \"\"\n",
    "\n",
    "    for i in range(len(song)):\n",
    "        #add the caracter to the line\n",
    "        line+=song[i]\n",
    "        #check two following caracters to spot the \\\\n\n",
    "        if song[i]==\"\\n\" :\n",
    "            #cut the str to end the line\n",
    "            song_lyrics.append(line[:len(line)-2])\n",
    "            #start another line\n",
    "            line =''\n",
    "            \n",
    "    return song_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequences(encoded_text, sequence_length):\n",
    "    sequences = []\n",
    "    n_sequences = int(len(encoded_text)/sequence_length)\n",
    "    for i in range(n_sequences):\n",
    "        sequences.append(encoded_text[i*sequence_length:(i+1)*sequence_length])\n",
    "    return(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence(seq, max_length, pad_label=100):\n",
    "    \n",
    "    seq += [pad_label for i in range(max_length - len(seq))]\n",
    "    \n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_str(n_songs, df):\n",
    "    \"\"\"concatenate lyrics from the n_songs of a df\"\"\"\n",
    "    songs_conc = \"\"\n",
    "    for i in range(n_songs):\n",
    "        songs_conc += df.iloc[i].text\n",
    "    return songs_conc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embeds_array(array, n_chars, n_sequences, max_sequence_length):\n",
    "    \"\"\"inputs : 2 dim array of padded encoded sequences and number of char\n",
    "    outputs : 3 dim array, replace each encoded char by a one hot vector\"\"\"\n",
    "    \n",
    "    #create an empty array of the rigth dimension\n",
    "    output = np.zeros((n_sequences, max_sequence_length, n_chars+1))\n",
    "\n",
    "    for seq in range(n_sequences):\n",
    "        for char in range(max_sequence_length):\n",
    "            label = array[seq][char]\n",
    "            #100 = pad label\n",
    "            if label != 100 : \n",
    "                output[seq][char][label] = 1\n",
    "            else :\n",
    "                #replace the first number by 1 (pad label)\n",
    "                #char_to_ix has been made to start at 1 for the first character\n",
    "                output[seq][char][0] = 1\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embeds_array_wp(array, n_chars, n_sequences, max_sequence_length):\n",
    "    \"\"\"inputs : 2 dim array of padded encoded sequences and number of char\n",
    "    outputs : 3 dim array, replace each encoded char by a one hot vector\"\"\"\n",
    "    \n",
    "    #create an empty array of the rigth dimension\n",
    "    output = np.zeros((n_sequences, max_sequence_length, n_chars))\n",
    "\n",
    "    for seq in range(n_sequences):\n",
    "        for char in range(max_sequence_length):\n",
    "            label = array[seq][char] \n",
    "            output[seq][char][label] = 1\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shaping data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load df\n",
    "df, n_songs = load_data(\"songdata.csv\",['Elton John', 'Eminem'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#gather songs in one big str\n",
    "songs_conc = concat_str(n_songs, df)\n",
    "#create a list of the lines of our dataset\n",
    "sequences = split_lines(songs_conc)\n",
    "#change char for matching char to ix index\n",
    "encoded_sequences = [seq_encoder(sequences[i], char_to_ix) for i in range(len(sequences))]\n",
    "#remove empty sequences\n",
    "encoded_sequences = [encoded_sequences[i] for i in range(len(encoded_sequences)) if len(encoded_sequences[i])>1]\n",
    "#pad sequences according to the longest setence in the all df \n",
    "#in this way the nn dimensions are independent of the chosen artist\n",
    "encoded_padded_sequences = [pad_sequence(encoded_sequences[i], max_sentence_length) for i in range(len(encoded_sequences))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 50\n",
    "#gather songs in one big str\n",
    "songs_conc = concat_str(n_songs,df)\n",
    "#change char for matching char_to_ix index\n",
    "encoded_sequences = seq_encoder(songs_conc, char_to_ix)\n",
    "#split text in size learnable sequences\n",
    "encoded_split_sequences = split_sequences(encoded_sequences, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sequences = len(encoded_split_sequences)\n",
    "\n",
    "#slice inputs and outputs by one char\n",
    "inputs = [encoded_split_sequences[i][:-1] for i in range(n_sequences)]\n",
    "outputs = [encoded_split_sequences[i][1:] for i in range(n_sequences)]\n",
    "        \n",
    "#embeds the inputs and outputs\n",
    "inputs_embedded = embeds_array_wp(array = inputs, n_chars = len(char_to_ix), \n",
    "                               n_sequences = n_sequences, \n",
    "                               max_sequence_length = sequence_length-1)\n",
    "\n",
    "outputs_embedded = embeds_array_wp(array = outputs, n_chars = len(char_to_ix), \n",
    "                               n_sequences = n_sequences, \n",
    "                               max_sequence_length = sequence_length-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_inputs = inputs_embedded[:1000]\n",
    "lit_outputs = outputs_embedded[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters :\n",
    "hidden_dim = 500\n",
    "num_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.LSTM(hidden_dim, input_shape=(None, len(char_to_ix)), return_sequences=True))\n",
    "for i in range(num_layers - 1):\n",
    "    model.add(keras.layers.LSTM(num_layers, return_sequences=True))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "model.add(keras.layers.TimeDistributed(keras.layers.Dense(len(char_to_ix))))\n",
    "model.add(keras.layers.Activation('softmax'))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, length, vocab_size):\n",
    "    \n",
    "    ix = [np.random.randint(1,vocab_size)]\n",
    "    y_char = [ix_to_char[ix[-1]]]\n",
    "    X = np.zeros((1, length, vocab_size))\n",
    "    \n",
    "    for i in range(length):\n",
    "        #fill the one hot vector of the corresponding caracter\n",
    "        X[0, i, :][ix[-1]] = 1\n",
    "        print(ix_to_char[ix[-1]], end=\"\")\n",
    "        ix = np.argmax(model.predict(X[:, :i+1, :])[0], 1)\n",
    "        y_char.append(ix_to_char[ix[-1]])\n",
    "    return y_char"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** epoch 0 *****\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taboga/virtualenvs/env1/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 1s 5ms/step - loss: 4.3074\n",
      "***** epoch 1 *****\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 4.3002\n",
      "***** epoch 2 *****\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 4.2934\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print('***** epoch '+str(epoch)+\" *****\")\n",
    "    model.fit(lit_inputs, lit_outputs, batch_size=int(n_sequences/4), verbose=1, nb_epoch=1)\n",
    "    if epoch % 1 == 0:\n",
    "        model.save_weights('checkpoint_{}_epoch_{}.hdf5'.format(hidden_dim, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh"
     ]
    }
   ],
   "source": [
    "new_song = generate_text(model, 50, len(char_to_ix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
